\section{Introduction}
\subsection{Background}
In recent years, unmanned aerial vehicles (UAVs),
commonly referred to as drones,
have become popular amongst consumers.
There has also been an upsurge in usage by emergency services.
These drones are fitted with a camera to record flights, stream video footage, or to help  with piloting.
Unfortunately, cameras are subject to turbulence due to aerodynamic effects which create unwanted jitters in any videos. 
In more advanced drones, video quality is increased using a gimbal which attempts real time compensation of the turbulence,
however a digital approach to video stabilisation provides useful information such as the motion model of the camera.

Video stabilisation can be used to compensate all motions or remove high frequency jitters.
Removal of high frequency jitters is useful for applications in stabilization of video streams
where the camera motion is unimportant such as astronomy where motion is caused by atmospheric effects. 
Our work is concerned with the former case, which has the advantage of providing contextual information on the surroundings of each frame in the video.  


In this paper, we describe an algorithm to estimate the motion of the camera.
An analysis of the numerical errors of the algorithm is performed.
We demonstrate how the global motion information can be used to construct a panoramic image from drone footage.
This method produces an image or video with significantly higher resolution than the original video dimensions. 
Applications of this include mapping of areas with greater resolution than is available with the camera being used, by recording a video of the drone passing over the area of the desired image.
Another possible use is to show the path taken by an object being tracked by the drone.

